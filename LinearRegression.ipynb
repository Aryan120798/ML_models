{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "3bMRNIatIs0Y"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qMgIQO7bOK8X"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Housing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SYc9Tf-PSyDU",
        "outputId": "644f395f-f68c-4ef9-b938-701a8c034cc5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-2.3</th>\n",
              "      <th>0.568</th>\n",
              "      <th>4.78</th>\n",
              "      <th>3.99</th>\n",
              "      <th>3.17</th>\n",
              "      <th>0.125</th>\n",
              "      <th>0.11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.568</td>\n",
              "      <td>4.78</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.568</td>\n",
              "      <td>4.78</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.568</td>\n",
              "      <td>4.78</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.568</td>\n",
              "      <td>4.78</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.225</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.568</td>\n",
              "      <td>4.78</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.250</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   -2.3  0.568  4.78  3.99  3.17  0.125  0.11\n",
              "0  -2.3  0.568  4.78  3.99  3.17  0.150  0.27\n",
              "1  -2.3  0.568  4.78  3.99  3.17  0.175  0.47\n",
              "2  -2.3  0.568  4.78  3.99  3.17  0.200  0.78\n",
              "3  -2.3  0.568  4.78  3.99  3.17  0.225  1.18\n",
              "4  -2.3  0.568  4.78  3.99  3.17  0.250  1.82"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "5JP3LpYiV4Y4"
      },
      "outputs": [],
      "source": [
        "X = df.values[:,:-1]\n",
        "y = df.values[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "9uAAhmcpIs0a"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, X, y, max_iteration, epsilon, lambda_, learning_rate, sgd, gd=True, regularization=True, batch_size = None) -> None:\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_iteration = max_iteration\n",
        "        self.epsilon = epsilon\n",
        "        self.lambda_ = lambda_\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sgd = sgd\n",
        "        self.gd = gd\n",
        "        self.regularization = regularization\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def split_data(self):\n",
        "      X_train, X_test, y_train, y_test = train_test_split(self.X,\n",
        "                                                          self.y,\n",
        "                                                          test_size=0.3,\n",
        "                                                          shuffle= True)\n",
        "      return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def add_X0(self, X):\n",
        "      return np.column_stack([np.ones([X.shape[0], 1]), X])\n",
        "\n",
        "    def normalize_train(self,X):\n",
        "      mean = np.mean(X, axis = 0)\n",
        "      std = np.std(X, axis = 0)\n",
        "      X = (X - mean) / std\n",
        "      X = self.add_X0(X)\n",
        "      return X, mean, std\n",
        "\n",
        "    def normalize_test(self, X, mean, std):\n",
        "      X = (X - mean) / std\n",
        "      X = self.add_X0(X)\n",
        "      return X\n",
        "\n",
        "    def rank(self, X):\n",
        "      u, s, v = np.linalg.svd(X)\n",
        "      return len([x for x in s if x > 0.0005])\n",
        "\n",
        "    def check_fullRank(self,X):\n",
        "      rank = self.rank(X)\n",
        "      if rank == min(X.shape):\n",
        "        self.full_rank = True\n",
        "        print(\"it is full rank\")\n",
        "      else:\n",
        "        self.full_rank = False\n",
        "        print(\"it is not full rank\")\n",
        "\n",
        "    def check_lowRank(self, X):\n",
        "      if X.shape[0] < X.shape[1]:\n",
        "        self.low_rank = True\n",
        "        print(\"it is low rank\")\n",
        "      else:\n",
        "        self.low_rank = False\n",
        "        print(\"it is not low rank\")\n",
        "\n",
        "    def closed_form_solution(self, X, y):\n",
        "    #Adding the penalty term as L2 Norm\n",
        "      if self.regularization == True:\n",
        "        self.theta = np.linalg.inv(X.T.dot(X) + self.lambda_ * np.identity(X.shape[1])).dot(X.T).dot(y)\n",
        "      else:\n",
        "        self.theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "      return self.theta\n",
        "\n",
        "    def predict(self, X):\n",
        "      return X.dot(self.theta)\n",
        "\n",
        "    def sse(self, X, y):\n",
        "      y_hat = self.predict(X)\n",
        "      return ((y_hat - y) ** 2).sum()\n",
        "\n",
        "    def cost_function(self, X, y):\n",
        "      loss = self.sse(X, y)\n",
        "      return loss / 2\n",
        "    \n",
        "    def cost_derivative(self, X, y):\n",
        "      if self.regularization == True:\n",
        "        y_hat = self.predict(X)\n",
        "        return (X.T.dot(y_hat - y) + self.lambda_ * self.theta)\n",
        "      else:\n",
        "        y_hat = self.predict(X)\n",
        "        return X.T.dot(y_hat - y)\n",
        "\n",
        "    def gradient_descent(self, X, y):\n",
        "      errors = []\n",
        "      prev_error = float(\"inf\")\n",
        "\n",
        "      for t in tqdm(range(self.max_iteration), colour = 'blue'):\n",
        "        self.theta -= self.learning_rate * self.cost_derivative(X, y)\n",
        "        error = self.cost_function(X, y)\n",
        "        errors.append(error)\n",
        "\n",
        "        if abs(error - prev_error) < self.epsilon:\n",
        "          print(\"Model stopped learning\")\n",
        "          break\n",
        "\n",
        "      self.plot_rmse(errors)\n",
        "      \n",
        "    def stocastic_gradient_descent(self, X, y):\n",
        "      errors = []\n",
        "      prev_error = float(\"inf\")\n",
        "      \n",
        "      print(\"Batch size: \" + str(int(len(y) * self.batch_size)))\n",
        "      \n",
        "      self.slice_rowsX = int(X.shape[0] * self.batch_size)\n",
        "      self.slice_rowsy = int(len(y) * self.batch_size)\n",
        "      \n",
        "      #slice X till batch_size\n",
        "      sgdX = X[:self.slice_rowsX, :]\n",
        "      sgdy = y[:self.slice_rowsy]\n",
        "\n",
        "      for t in tqdm(range(self.max_iteration), colour = 'blue'):\n",
        "        self.theta -= self.learning_rate * self.cost_derivative(sgdX, sgdy)\n",
        "        error = self.cost_function(sgdX, sgdy)\n",
        "        errors.append(error)\n",
        "\n",
        "        if abs(error - prev_error) < self.epsilon:\n",
        "          print(\"Model stopped learning\")\n",
        "          break\n",
        "\n",
        "      self.plot_rmse(errors)\n",
        "\n",
        "    def fit(self):\n",
        "      X_train, X_test, y_train, y_test = self.split_data()\n",
        "      X_train, mean, std = self. normalize_train(X_train)\n",
        "      X_test = self.normalize_test(X_test, mean, std)\n",
        "      self.check_fullRank(X_train)\n",
        "      self.check_lowRank(X_train)\n",
        "\n",
        "      if self.full_rank and not self.low_rank and X_train.shape[1] < 1000 and not self.gd and not self.sgd:\n",
        "          print(\"Closed form solution\")\n",
        "          self.closed_form_solution(X_train, y_train)\n",
        "      elif self.gd or self.low_rank:\n",
        "        print(\"Gradient Descent\")\n",
        "        self.theta = np.ones(X_train.shape[1])\n",
        "        self.gradient_descent (X_train, y_train)\n",
        "      else:\n",
        "        print(\"Stochastic Gradient Descent\")\n",
        "        self.theta = np.ones(X_train.shape[1])\n",
        "        self.stocastic_gradient_descent(X_train, y_train)\n",
        "\n",
        "      print(self.theta)\n",
        "\n",
        "\n",
        "    def plot_rmse(self, error_sequence):\n",
        "        \"\"\"\n",
        "        @X: error_sequence, vector of rmse\n",
        "        @does: Plots the error function\n",
        "        @return: plot\n",
        "        \"\"\"\n",
        "        # Data for plotting\n",
        "        s = np.array(error_sequence)\n",
        "        t = np.arange(s.size)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(t, s)\n",
        "\n",
        "        ax.set(xlabel='iterations', ylabel=list(range(len(error_sequence))))\n",
        "        ax.grid()\n",
        "\n",
        "        plt.legend([\"Error Curve\"], bbox_to_anchor=(1.05,1), loc=2, shadow=True)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "0LwmNqBIVvLl",
        "outputId": "9112bdb2-9510-4f22-adf1-709bba3d011f"
      },
      "outputs": [],
      "source": [
        "# Closed form solution \n",
        "# Regularization = True\n",
        "\n",
        "# lr = LinearRegression(X, y, max_iteration=50, epsilon=0.003, learning_rate=0.001, lambda_ = 0.01,\n",
        "#                       sgd = False, \n",
        "#                       gd = False, \n",
        "#                       regularization=True)\n",
        "# lr.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Closed form solution \n",
        "# Regularization = False\n",
        "\n",
        "# lr = LinearRegression(X, y, max_iteration=50, epsilon=0.003, learning_rate=0.001, lambda_ = 0.01,\n",
        "#                       sgd = False, \n",
        "#                       gd = False, \n",
        "#                       regularization=False)\n",
        "# lr.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gradient Descent \n",
        "# Regularization = True\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# lr = LinearRegression(X, y, max_iteration=1500, epsilon=0.03, learning_rate=0.00001, lambda_ = 0.01,\n",
        "#                       sgd = False, \n",
        "#                       gd = True, \n",
        "#                       regularization=True)\n",
        "# lr.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gradient Descent \n",
        "# Regularization = Fasle\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# lr = LinearRegression(X, y, max_iteration=1500, epsilon=0.03, learning_rate=0.00001, lambda_ = 0.01,\n",
        "#                       sgd = False, \n",
        "#                       gd = True, \n",
        "#                       regularization=False)\n",
        "\n",
        "# lr.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stocastic Gradient Descent \n",
        "# Regularization = True\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# lr = LinearRegression(X, y, max_iteration=1500, epsilon=0.03, learning_rate=0.00001, lambda_ = 0.01,\n",
        "#                       batch_size=0.3,\n",
        "#                       sgd = True, \n",
        "#                       gd = False, \n",
        "#                       regularization=True)\n",
        "\n",
        "# lr.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stocastic Gradient Descent \n",
        "# Regularization = False\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# lr = LinearRegression(X, y, max_iteration=1500, epsilon=0.03, learning_rate=0.00001, lambda_ = 0.01,\n",
        "#                       batch_size=0.3,\n",
        "#                       sgd = True, \n",
        "#                       gd = False, \n",
        "#                       regularization=False)\n",
        "\n",
        "# lr.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
