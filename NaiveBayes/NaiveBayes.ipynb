{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from dataclasses import dataclass\n",
    "import sklearn\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcluster_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter_box\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_centers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate isotropic Gaussian blobs for clustering.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int or array-like, default=100\n",
      "    If int, it is the total number of points equally divided among\n",
      "    clusters.\n",
      "    If array-like, each element of the sequence indicates\n",
      "    the number of samples per cluster.\n",
      "\n",
      "    .. versionchanged:: v0.20\n",
      "        one can now pass an array-like to the ``n_samples`` parameter\n",
      "\n",
      "n_features : int, default=2\n",
      "    The number of features for each sample.\n",
      "\n",
      "centers : int or array-like of shape (n_centers, n_features), default=None\n",
      "    The number of centers to generate, or the fixed center locations.\n",
      "    If n_samples is an int and centers is None, 3 centers are generated.\n",
      "    If n_samples is array-like, centers must be\n",
      "    either None or an array of length equal to the length of n_samples.\n",
      "\n",
      "cluster_std : float or array-like of float, default=1.0\n",
      "    The standard deviation of the clusters.\n",
      "\n",
      "center_box : tuple of float (min, max), default=(-10.0, 10.0)\n",
      "    The bounding box for each cluster center when centers are\n",
      "    generated at random.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "return_centers : bool, default=False\n",
      "    If True, then return the centers of each cluster.\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The generated samples.\n",
      "\n",
      "y : ndarray of shape (n_samples,)\n",
      "    The integer labels for cluster membership of each sample.\n",
      "\n",
      "centers : ndarray of shape (n_centers, n_features)\n",
      "    The centers of each cluster. Only returned if\n",
      "    ``return_centers=True``.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_classification : A more intricate variant.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import make_blobs\n",
      ">>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "...                   random_state=0)\n",
      ">>> print(X.shape)\n",
      "(10, 2)\n",
      ">>> y\n",
      "array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      ">>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
      "...                   random_state=0)\n",
      ">>> print(X.shape)\n",
      "(10, 2)\n",
      ">>> y\n",
      "array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.11/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "make_blobs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_blobs(n_samples = 10000, n_features = 2, centers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.74905974 -3.98765136]\n",
      " [ 9.27196757 -5.13814732]\n",
      " [ 6.30101368 -4.23083817]\n",
      " [10.44921614 -6.65233778]\n",
      " [10.49850066 -5.74158534]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points about NB:\n",
    "- Generative model\n",
    "- Non-parametric model\n",
    "- It assumes a gaussian distribution for every column of each class\n",
    "- It naively assumes that columns are independent\n",
    "  \n",
    "\n",
    "- It doesn't have any hyper-parameters\n",
    "\n",
    "What do we need:\n",
    "- Prior Distribution\n",
    "- Likelihood\n",
    "- Posterior ~ Likelihood * Prior\n",
    "- Datasplit\n",
    "\n",
    "Gaussian_PDF = 1/(sqrt(2 * pi * var) * (exp(-(x_i - mean)**2/2var))\n",
    "p(y_i = k | x_i) ~ P(x_i_0 | y = k) * P(x_i_1 | y = k) * P(y=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GaussianNaiveBayes:\n",
    "    # def __init__(self, X, y):\n",
    "    #     self.X = X\n",
    "    #     self.y = y\n",
    "    X: np.array\n",
    "    y: np.array\n",
    "\n",
    "    def __post_init__(self): #series of steps that you want your class object to execute/ initiate as soon as someone initiates the class without a need to ask the user\n",
    "        self.dataSplit()\n",
    "        \n",
    "        self.X0_train = self.X_train[self.y_train == 0]\n",
    "        self.X1_train = self.X_train[self.y_train == 1]\n",
    "        self.y0_train = self.y_train[self.y_train == 0]\n",
    "        self.y1_train = self.y_train[self.y_train == 1]\n",
    "\n",
    "        self.fit()\n",
    "        self.predict()\n",
    "    #a new thing taught about data class\n",
    "\n",
    "    def dataSplit(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = sklearn.model_selection.train_test_split(self.X, self.y, test_size = 0.3, shuffle = True)\n",
    "\n",
    "    def fit_distribution(self, x): #we are passing one column at a time\n",
    "        mean = np.mean(x)\n",
    "        std = np.std(x)\n",
    "        dist = norm(mean, std)\n",
    "        return dist \n",
    "\n",
    "    def posterior(self, x, prior, dist_col1, dist_col2):\n",
    "        return prior * dist_col1.pdf(x[0]) * dist_col2.pdf(x[1]) # dist_col1.pdf(x[0]) is the likelihood of that point in that distribution\n",
    "        \n",
    "    def fit(self):\n",
    "        self.prior_y0 = len(self.y0_train) / len(self.y)\n",
    "        self.prior_y1 = len(self.y1_train) / len(self.y)\n",
    "\n",
    "        #Distribution of every column in each class\n",
    "        \n",
    "        self.dist_X_0_0 = self.fit_distribution(self.X0_train[:,0])\n",
    "        self.dist_X_0_1 = self.fit_distribution(self.X0_train[:,1])\n",
    "\n",
    "        self.dist_X_1_0 = self.fit_distribution(self.X1_train[:,0])\n",
    "        self.dist_X_1_1 = self.fit_distribution(self.X1_train[:,1])\n",
    "\n",
    "    def predict(self):\n",
    "\n",
    "        self.error_count = 0\n",
    "\n",
    "        for sample, target in zip(self.X_test, self.y_test):\n",
    "            py0 = self.posterior(sample, self.prior_y0, self.dist_X_0_0, self.dist_X_0_1)\n",
    "            py1 = self.posterior(sample, self.prior_y1, self.dist_X_1_0, self.dist_X_1_1)\n",
    "\n",
    "            #print('P(y=0 | %s) = %3.f' % (sample, py0 * 100))\n",
    "            #print('P(y=1 | %s) = %3.f' % (sample, py1 * 100))\n",
    "\n",
    "            if np.argmax([py0,py1]) != target:\n",
    "                self.error_count += 1\n",
    "        \n",
    "            #print(\" Model predicted class {} and the truth was: {} \\n\".format(np.argmax([py0,py1]), target))\n",
    "\n",
    "        print(self.error_count)\n",
    "        print(len(self.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNaiveBayes(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prophet39",
   "language": "python",
   "name": "prophet39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
